assign(paste0('p_vals',k,'_pow'), vector("list", 4)) # List for 4 methods
}
for(i in 1:4){
for(j in 1:n_rep){
for(k in 1:n_M){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',k,'_t1err[[',i,']] <- append(p_vals',k,'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',k,'_pow[[',i,']] <- append(p_vals',k,'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[k] = n_p[k] + 1; }
}
}
}
level <- .05
# Power
for(k in 1:n_M){
eval(parse(text=paste0('power_mat[',k,',] <- unlist(lapply(p_vals',k,'_pow, function(x) mean(x<level)))')))
}
power_mat
res[[6]][[1]]
props <- seq(0,100,by=20)
n_pvals <- NULL
for(k in 1:n_M){
eval(parse(text=paste0('type1err[',k,',] <- unlist(lapply(p_vals',k,'_t1err, pvals_analysis, al = .05))')))
eval(parse(text=paste0('n_pvals[',k,'] <- length(p_vals',k,'_t1err[[1]])')))
}
write.table(type1err, row.names=FALSE, quote=FALSE); t(sapply(n_pvals, function(x).05 + c(-1,1)*2*sqrt(.05*(1-.05)/x)))
png("t1err_plot%d.png", width = 12, height = 9, units = 'in', res=200)
par(mfrow = c(2,2))
for(k in 1:n_M){
eval(parse(text=paste0('lapply(1:4, draw_pval, p_vals',k,'_t1err, method_used)')))
title(paste('Polygenic effect / Covariates:',props[k],'/',100-props[k]), outer=TRUE, cex=1.1, line = -1.5)
}
dev.off()
library(Hmisc)
plot_power(power_mat)
p_vals6_t1err
str(p_vals6_t1err)
summary(p_vals6_t1err[[1]])
hist(p_vals6_t1err[[1]])
min(p_vals6_t1err[[1]])
head(sort(p_vals6_t1err[[1]]))
head(sort(p_vals6_t1err[[2]]))
require(MCMCglmm)
?MCMCglmm
?rbeta
edit(rbeta)
edit(rbeta)
library(Matrix)
?Matrix::`dgCMatrix-class`
?as
?cor
?cov
edit(cov)
sum(c(1,2),c(5,10))
sum(as.vector(c(1,2)),as.vector(c(5,10)))
c(1,2)+c(5,10))
c(1,2)+c(5,10)
?scale
?dcauchy
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With related individuals + missing G/Type 1 error + power/old settings/.RData")
res
sqrt(.05*.95/5000)
?predcit.MCMCglmm
?MCMCglmm::predict.MCMCglmm
edit(predict.MCMCglmm)
library(MCMCglmm)
edit(predict.MCMCglmm)
edit(predict.MCMCglmm)
?@
?'@'
n_M
n_M@
n_M
slot(Prec,x)
slot(Prec,n_M)
slot(Prec)
slot(Prec,"attr")
slotNames(Prec)
Prec@i
Prec@x
Prec$x
str(Prec)
str(Prec@x)
dim(Prec@x)
edit(predict.MCMCglmm)
update.packages("MCMCglmm")
edit(MCMCglmm::predict.MCMCglmm())
edit(MCMCglmm::predict.MCMCglmm
)
predict.MCMCglmm
update.packages("MCMCglmm")
sqrt(.25*.75*500)
sqrt(.25*.75)
sqrt(.25*.75/500)
sqrt(.25*.75/500)*100
sqrt(.25*.75/1000)*100
sqrt(.25*.75/2000)*100
sqrt(.25*.75*2000)/2000*100
.25*2000
sqrt(.25*.75*2000)
172*2
414+344+242
sqrt(1-.6^2)*15
(80-65)/20*.6
.45*15+75
(85-65)/20*.6
.6*15+75
sqrt(1/10*9/10)*sqrt(1000)
1/10*2000
sqrt(3/10*7/10)*sqrt(1000)
pnorm(310,300,14.49,lower.tail = F)
pnorm(110,100,9.49,lower.tail = F)
100
10/6
12/6
sqrt(2/6*4/6)*6*sqrt(100)
sd(rep(c(0,6),c(4,2))*sqrt(100)
)
sd(rep(c(0,6),c(4,2)))*sqrt(100)
sd(rep(c(0,6),c(4,2)))*sqrt(100*5/6)
2*100
sqrt(2/6*4/6)*6*sqrt(100)
sqrt(2/6*4/6)*sqrt(100)
2/6
2/6*100
pnorm(35,2/6*100,4.714045,lower.tail = F)
100-1/6*10
1/6*100
100-14-10-17
2/6*100
100-14-10-17-40
1/6*100
sqrt(1/6*5/6)*sqrt(100)
(19-16.67)/3.72678
.4
2/6
sqrt(2/6*4/6)/sqrt(100)
sqrt(2/6*4/6)/sqrt(100)*100
(40-33.33)/4.71
sd(c(-4,-3,-1,0,6,6))*sqrt(5/6)
mean(c(-4,-3,-1,0,6,6))
4/sqrt(100)
mean(c(-4,-3,-1,0,6,6))*100
4*sqrt(100)
mean(c(-4,-3,-1,0,6,6))*200
4*sqrt(200)
pnorm(120,133,56.6,lower.tail = F)
54/500
sqrt(0.108*(1-0.108)/500)
.108+c(-1,1)*2*sqrt(0.108*(1-0.108)/500)
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Type 1 error + power/using lmm on u/w MATSOR-GLS/.RData")
setwd("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Type 1 error + power/using lmm on u/w MATSOR-GLS/")
ls()
M
sapply(res,length)
res[[1]][[1]]
matrix(1:6,2,3)
plot_power <- function(power_mat, meth_list){
props <- seq(0,100,by=20)[(na_i <- n_p > 0)]
sds <- 2*sqrt(.25 / n_p[na_i])
n_method <- length(meth_list)
pdf("power_plot.pdf")
errbar(props, (y<-power_mat[na_i,1]), y+sds, y-sds, type = "b", pch=16, col='red', errbar.col = 'red', ylim = c(0,1), cap = .03,
ylab = "Power", xlab = "Proportion of variance on logit scale due to polygenic effects/covariates", xaxt = "n" )
for(i in 2:n_method){
errbar(props, (y<-power_mat[na_i,i]), y+sds, y-sds, type = "b",add=T, cap = .03,pch = c(15,17,18)[i-1], col=c('blue','lightgreen','purple')[i-1], errbar.col = c('blue','lightgreen','purple')[i-1])
}
axis(1, at = props, label = c("0/100", "20/80","40/60","60/40","80/20","100/0")[na_i])
legend('topright', horiz = F, legend = meth_list, pch = c(16,15,17,18)[1:n_method] , col = c('red','blue','lightgreen','purple')[1:n_method], cex=1.4, bty="n")
dev.off()
}
pvals_analysis <- function(p_vals, al){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result$Err_rate[alpha==al]
}
draw_pval <- function(ind, p_vals_list, meth_list, percent){
p_vals <- p_vals_list[[ind]]
method <- meth_list[ind]
n <- length(p_vals)
uni2 <- rank(p_vals, ties.method='max'); names(uni2)=c()
plot(-log10(uni2/(n+1)),-log10(p_vals), type="n", ylab=expression('Observed (-log'[10]*' p-value)'), xlab=expression('Expected (-log'[10]*' p-value)'))
a=1:n
high <- qbeta(0.025, a, rev(a))
low <- qbeta(0.975, a, rev(a))
polygon(-log10(c(a/n,rev(a/n))), -log10(c(high, rev(low))), col ='gray', border = NA)
points(-log10(uni2/(n+1)),-log10(p_vals), pch=16,cex=.3)
title(expression(bold('Plot of observed vs. expected -log'[10]*' p-values')),line=2)
title(paste('With', method), line=.5)
abline(a=0,b=1,col="red")
}
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Type 1 error + power/using lmm on u/w GLS/.RData")
setwd("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Type 1 error + power/using lmm on u/w GLS/")
M
n_p=rep(0, 6)
method_used = c('MCMCglmm_GLS', ,'CARAT')
n_p=rep(0, 6)
method_used = c('MCMCglmm_GLS', 'CARAT')
power_mat = matrix(NA, 6, 4)
type1err <- matrix(NA, 6, 4, dimnames = list(NULL, method_used))
n_pvals <- NULL
index <- ((1:6)[round((0:5)*.2, 1) %in% M[,1]])[sapply(res,length) > 0]
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", 4)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", 4)) # List for 4 methods
}
index
M
for(i in 1:4){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[index[k]] = n_p[index[k]] + 1; }
}
}
}
# index <- 1:6
level <- .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',index[k],',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
plot_power(power_mat, method_used)
# Type 1 Error
props <- seq(0,100,by=20)
for(k in 1:length(index)){
eval(parse(text=paste0('type1err[',index[k],',] <- unlist(lapply(p_vals',index[k],'_t1err, pvals_analysis, al = .05))')))
eval(parse(text=paste0('n_pvals[',k,'] <- length(p_vals',index[k],'_t1err[[1]])')))
}
type1err;t(sapply(n_pvals, function(x).05 + c(-1,1)*2*sqrt(.05*(1-.05)/x)))
png("t1err_plot%01d.png", width = 12, height = 9, units = 'in', res=200)
par(mfrow = c(2,2))
for(k in 1:length(index)){
eval(parse(text=paste0('lapply(1:4, draw_pval, p_vals',index[k],'_t1err, method_used)')))
title(paste('Polygenic effect / Covariates:',props[index[k]],'/',100-props[index[k]]), outer=TRUE, cex=1.1, line = -1.5)
}
dev.off()
n_p
n_pvals
n_p=rep(0, 6)
power_mat = matrix(NA, 6, 4)
type1err <- matrix(NA, 6, 4, dimnames = list(NULL, method_used))
n_meth <- length( (method_used = c('MCMCglmm', 'GMMAT','CARAT','CERAMIC')) )
power_mat = matrix(NA, 6, n_meth)
type1err <- matrix(NA, 6, n_meth, dimnames = list(NULL, method_used))
n_pvals <- NULL
index <- ((1:6)[round((0:5)*.2, 1) %in% M[,1]])[sapply(res,length) > 0]
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", n_meth)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", n_meth)) # List for 4 methods
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[index[k]] = n_p[index[k]] + 1; }
}
}
}
n_meth
n_meth <- length( (method_used = c('MCMCglmm_GLS','CARAT') )
)
n_p=rep(0, 6)
power_mat = matrix(NA, 6, n_meth)
type1err <- matrix(NA, 6, n_meth, dimnames = list(NULL, method_used))
n_pvals <- NULL
index <- ((1:6)[round((0:5)*.2, 1) %in% M[,1]])[sapply(res,length) > 0]
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", n_meth)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", n_meth)) # List for 4 methods
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[index[k]] = n_p[index[k]] + 1; }
}
}
}
level <- .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',index[k],',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
plot_power(power_mat, method_used)
dev.off()
level <- .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',index[k],',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
plot_power(power_mat, method_used)
props <- seq(0,100,by=20)
for(k in 1:length(index)){
eval(parse(text=paste0('type1err[',index[k],',] <- unlist(lapply(p_vals',index[k],'_t1err, pvals_analysis, al = .05))')))
eval(parse(text=paste0('n_pvals[',k,'] <- length(p_vals',index[k],'_t1err[[1]])')))
}
type1err;t(sapply(n_pvals, function(x).05 + c(-1,1)*2*sqrt(.05*(1-.05)/x)))
png("t1err_plot%01d.png", width = 12, height = 9, units = 'in', res=200)
par(mfrow = c(2,2))
for(k in 1:length(index)){
eval(parse(text=paste0('lapply(1:n_meth, draw_pval, p_vals',index[k],'_t1err, method_used)')))
title(paste('Polygenic effect / Covariates:',props[index[k]],'/',100-props[index[k]]), outer=TRUE, cex=1.1, line = -1.5)
}
dev.off()
n_p=rep(0, 6)
power_mat = matrix(NA, 6, n_meth)
type1err <- matrix(NA, 6, n_meth, dimnames = list(NULL, method_used))
n_pvals <- NULL
index <- ((1:6)[round((0:5)*.2, 1) %in% M[,1]])[sapply(res,length) > 0]
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", n_meth)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", n_meth)) # List for 4 methods
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[index[k]] = n_p[index[k]] + 1; }
}
}
}
# index <- 1:6
level <- .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',index[k],',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
plot_power(power_mat, method_used)
# Type 1 Error
props <- seq(0,100,by=20)
for(k in 1:length(index)){
eval(parse(text=paste0('type1err[',index[k],',] <- unlist(lapply(p_vals',index[k],'_t1err, pvals_analysis, al = .05))')))
eval(parse(text=paste0('n_pvals[',k,'] <- length(p_vals',index[k],'_t1err[[1]])')))
}
type1err;t(sapply(n_pvals, function(x).05 + c(-1,1)*2*sqrt(.05*(1-.05)/x)))
png("t1err_plot%01d.png", width = 12, height = 9, units = 'in', res=200)
par(mfrow = c(2,2))
for(k in 1:length(index)){
eval(parse(text=paste0('lapply(1:n_meth, draw_pval, p_vals',index[k],'_t1err, method_used)')))
title(paste('Polygenic effect / Covariates:',props[index[k]],'/',100-props[index[k]]), outer=TRUE, cex=1.1, line = -1.5)
}
dev.off()
M
index
index <- ((1:6)[round((0:5)*.2, 1) %in% M[,1]])[sapply(res,length) > 0]
load(".RData")
n_p=rep(0, 6)
power_mat = matrix(NA, 6, n_meth)
type1err <- matrix(NA, 6, n_meth, dimnames = list(NULL, method_used))
n_pvals <- NULL
index <- ((1:6)[round((0:5)*.2, 1) %in% M[,1]])[sapply(res,length) > 0]
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", n_meth)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", n_meth)) # List for 4 methods
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[index[k]] = n_p[index[k]] + 1; }
}
}
}
# index <- 1:6
level <- .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',index[k],',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
plot_power(power_mat, method_used)
# Type 1 Error
props <- seq(0,100,by=20)
for(k in 1:length(index)){
eval(parse(text=paste0('type1err[',index[k],',] <- unlist(lapply(p_vals',index[k],'_t1err, pvals_analysis, al = .05))')))
eval(parse(text=paste0('n_pvals[',k,'] <- length(p_vals',index[k],'_t1err[[1]])')))
}
type1err;t(sapply(n_pvals, function(x).05 + c(-1,1)*2*sqrt(.05*(1-.05)/x)))
png("t1err_plot%01d.png", width = 12, height = 9, units = 'in', res=200)
par(mfrow = c(2,2))
for(k in 1:length(index)){
eval(parse(text=paste0('lapply(1:n_meth, draw_pval, p_vals',index[k],'_t1err, method_used)')))
title(paste('Polygenic effect / Covariates:',props[index[k]],'/',100-props[index[k]]), outer=TRUE, cex=1.1, line = -1.5)
}
dev.off()
ls()
Gmat <- Phimat
res_fam <- sex
sex
dim(Gmat)
length(sex)
head(colSums(Gmat * res_fam)^2)
head(as.vector(crossprod(Gmat, res_fam))^2)
mafs <- colMeans(Gmat) / 2
ls()
fam_data$U_hat_cen <- sex
fam_data <- data.frame(U_hat_cen = sex)
str(fam_data$U_hat_cen )
res_fam <- crossprod(Prec, fam_data$U_hat_cen)
T_num <- colSums(Gmat * res_fam)^2
length(res_fam)
dim(Gmat)
matix(1:10,5,2) * 1:5
matrix(1:10,5,2) * 1:5
str(res_fam)
res_fam <- as.matrix(crossprod(Prec, fam_data$U_hat_cen))
T_num <- colSums(Gmat * res_fam)^2
res_fam <- as.vector(crossprod(Prec, fam_data$U_hat_cen))
T_num <- colSums(Gmat * res_fam)^2
length(T_num)
head(T_num)
mafs <- colMeans(Gmat) / 2
T_denum <- 2 * mafs * (1 - mafs) * sum(fam_data$U_hat_cen * res_fam)
head(T_denum)
1:4 * 2:5
get_denum_retro <- function(G, Matdenum){
mafs <- colMeans(G) / 2
2 * mafs * (1 - mafs) * Matdenum
}
YPhiY <- crossprod(res_fam, Phimat) %*% (res_fam) #marginal mean
T_denum1 <- get_denum_retro(Gmat, YPhiY)
head(T_denum)
head(T_denum1)
matrix(1:9,3,3)
matrix(1:9,3,3)-1:3
t(t(matrix(1:9,3,3))-1:3)
t(t((M<-matrix(1:9,3,3)))-1:3)
t(t(M)-1:3)
t(t(M)-colMeans(M))
t(t(M)-colMeans(M))
scale(M, scale=F)
scale(M, scale=FALSE)
scale(M, scale=TRUE)
M <- matrix(1:16,4,4)
scale(M, scale=TRUE)
scale(M, scale=FALSE)
t(t(M)-colMeans(M))
colSums(scale(M, scale = FALSE) * 1:4)^2
colSums(scale(M, scale = FALSE) * 5:8)^2
colSums(scale(M, scale = FALSE) * 5:8)
colSums(scale(M, scale = FALSE) * 1:4)
(scale(M, scale = FALSE) * 5:8)
(scale(M, scale = FALSE) * 1:4)
(scale(M, scale = FALSE) * -1:3)
(scale(M, scale = FALSE) * -1:2)
colSums(scale(M, scale = FALSE) * rnorm(4))^2
colSums(scale(M, scale = FALSE) * rnorm(4))^2
colSums(scale(M, scale = FALSE) * rnorm(4))^2
colSums(scale(M, scale = FALSE) * sample(1:10,4))^2
colSums(scale(M, scale = FALSE) * sample(1:10,4))^2
colSums(scale(M, scale = FALSE) * sample(1:10,4))^2
colSums(scale(M, scale = FALSE) * sample(1:10,4))^2
colSums(scale(M, scale = FALSE) * sample(1:10,4))^2
colSums(scale(M, scale = FALSE) * sample(1:10,4))^2
colSums(scale(M, scale = FALSE) * sample(1:10,4))^2
colSums(scale(M, scale = FALSE) * sample(1:10,4))^2
colSums(scale(M, scale = FALSE) * sample(1:10,4))^2
M
colMeans(M)
mean(colMeans(M))
sum(M)/16
Phimat<-M
Phimat
rowMeans(Phimat) ;colMeans(Phimat)
Phimat-rowMeans(Phimat)
Phimat-colMeans(Phimat)
scale(Phimat, scale = FALSE) - rowMeans(Phimat)
M<- M + rnorm(4)
scale(Phimat, scale = FALSE) - rowMeans(Phimat)
M[1,4] = 10
M[1,2] = 5
scale(Phimat, scale = FALSE) - rowMeans(Phimat)
Phimat=M
scale(Phimat, scale = FALSE) - rowMeans(Phimat)
colMeans(Phimat)
rowMeans(M)
M
res_fam
Phimat
Phimat = diag(N_fam) %x% phi
str(crossprod( crossprod(scale(Phimat, scale = FALSE) - rowMeans(Phimat) + sum(Phimat)/n_total^2, res_fam) , res_fam))
summary(res_fam)
T_num <- colSums(scale(Gmat, scale = FALSE) * res_fam)^2
T_denum <- .5 * g_bar * (2 - g_bar) * crossprod( crossprod(scale(Phimat, scale = FALSE) - rowMeans(Phimat) + sum(Phimat)/n_total^2, res_fam) , res_fam)
pvalstot <- pchisq(T_num / T_denum, df = 1, lower.tail = F)
res_fam <- as.vector(crossprod(Prec, fam_data$U_hat_cen))
g_bar <- colMeans(Gmat)
T_num <- colSums(scale(Gmat, scale = FALSE) * res_fam)^2
T_denum <- .5 * g_bar * (2 - g_bar) * crossprod( crossprod(scale(Phimat, scale = FALSE) - rowMeans(Phimat) + sum(Phimat)/n_total^2, res_fam) , res_fam)
pvalstot <- pchisq(T_num / T_denum, df = 1, lower.tail = F)
hist(pvalstot)
