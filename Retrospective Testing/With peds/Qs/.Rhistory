main = "Variance estimates over 200 Y realizations",
col = rep(c("turquoise","red"), each = n_M))
axis(1, at=1:n_M, labels=M[,1]*100)
abline(h= M[,1]*M[,2], col= rep("black",n_M), lty =2)
dev.off()
pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-05-2016/Project 2 - WS - Cauchy 10 - 50k Yp - 200Yr - 5pct thresh - w covs_unobsG/1 pct thresh/.RData")
p_valsMCMC <- vector("list", n_M) # List of size n_M
est_varMCMC <- vector("list", n_M)
m <- length(res[[1]][[1]]) # Number of pvals + est add var
for(i in 1:n_M) {
for (j in 1:n_rep){
if (!any(res[[i]][[j]][-m] < 0)) p_valsMCMC[[i]] <- append(p_valsMCMC[[i]], res[[i]][[j]][-m])
est_varMCMC[[i]] <- append(est_varMCMC[[i]], res[[i]][[j]][m])
}
}
pdf("pvals_WS_1pct.pdf")
for(i in 1:n_M) {
print(paste("Proportion of add_var : ", M[i,1]*100, "%", sep = ""))
summary(p_valsMCMC[[i]])
hist(p_valsMCMC[[i]], main="Using MCMCglmm estimates",freq = F, breaks=100, xlab="p-value")
title(bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"] ="~.(M[i,1]*100)*"%"),line=.7, cex.main = .9)
title(bquote("n ="~.(length(p_valsMCMC[[i]]))),line=-1, cex.main = .7)
abline(h=1,col="red")
}
boxplot(est_varMCMC, xaxt="n", ylab="Additive variance estimates",
xlab=bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"]   (in %)"),
main = "Variance estimates over 200 Y realizations",
col = rep(c("turquoise","red"), each = n_M))
axis(1, at=1:n_M, labels=M[,1]*100)
abline(h= M[,1]*M[,2], col= rep("black",n_M), lty =2)
dev.off()
pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
?COS
?cos
cos(18*pi/180)
76*sin(18*pi/180)
cos(18*pi/180)*76
cos(52*pi/180)*121
sin(52*pi/180)*121
23.485-146.775
sqrt(146.775^2+123.29^2)
a <- pi/180
75*cos(22*a)+117*cos(55*a)
75*sin(22*a)-117*sin(55*a)
75*sin(22*a)-117*sin((360-55)*a)
75*sin(22*a)+117*sin((360-55)*a)
sin(305*a)*117
75*sin(22*a)
28.1-95.8
69.5 +67.1
28.1+- 95.8
tanh(67.74529/136.6472)
?tan
atan(67.74529/136.6472)
atan(76.7/ 136.6 )
atan(67.74529/136.6472*a)
atan(67.74529/136.6472/a)
b=67.74529/136.6472
b
tanh(b)
atan(b)
atan(2)
b
tan(26.1*a)
tan(26.4*a)
arctan(.496)
atan(.496)
atan(67.6/136.6)
atan(67.6/136.6)/a
atan(b)/a
sin(305*a)
-sin(55*a)
121/76
121-76
72.3+74.5
76*cos(18*a)
76*sin(18*a)
121*sin(52*a)
121*cos(52*a)
72.3+74.5
23.5-95.3
23.485-95.349
sqrt(146.775^2+71.864^2)
23.5-95.3
sqrt(146.8^2+71.8^2)
atan(71.8/146.8)/a
23.5+95.3
sqrt(9.8*117.348/sin(2*27*pi/180))
x<-NULL
X = append(X, c(2:5))
x = append(x, c(2:5))
x
library(rmvnorm)
5 %in% 6:8
7 %in% 6:8
`+`(x,1)
x
libary(mvtnorm)
library(mvtnorm)
?rmvnorm
ep(x)
rep(x)
rmvnorm(1)
rmvnorm(1, mean = 0, sigma = diag(4))
rmvnorm(1, mean = rep(0,4), sigma = diag(4))
class(rmvnorm(1, mean = rep(0,4), sigma = diag(4)))
class(c(rmvnorm(1, mean = rep(0,4), sigma = diag(4))))
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-09-2016/Project 2 - WS - Cauchy 10 - 50k Yp - 200Yr - w covs_unobsG/1pct thresh/at 40%/B.RData")
lapply(p_valsMCMC, pvals_analysis)
pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
ls()
p_valsMCMC <- vector("list", n_M) # List of size n_M
est_varMCMC <- vector("list", n_M)
m <- length(res[[1]][[1]]) # Number of pvals + est add var
for(i in 1:n_M) {
for (j in 1:n_rep){
if (!any(res[[i]][[j]][-m] < 0)) p_valsMCMC[[i]] <- append(p_valsMCMC[[i]], res[[i]][[j]][-m])
est_varMCMC[[i]] <- append(est_varMCMC[[i]], res[[i]][[j]][m])
}
}
lapply(p_valsMCMC, pvals_analysis)
M = rbind(c(0,1.1))
n_M = dim(M)[1]
G1<-1:10
write.table(c("SNP1",G1),'geno.txt',row.names=FALSE, col.names=FALSE, sep='\t')
write(c("SNP1",G1),'geno.txt',row.names=FALSE, col.names=FALSE, sep='\t')
write(c("SNP1",G1),'geno.txt', sep='\t', ncolumns = 11)
library(GMMAT)
1078.94-925
start <- 1078.94-925
start + 50 + 120
start + 50 + 120 - 50 - 50 - 23
start + 50 + 120 - 50 - 50 - 23 - 1000
start + 50 + 120 - 50 - 50 - 23 - 1000 - 35
start + 50 + 120 - 50 - 50 - 23 - 1000 - 35 + 1035
176.63*1.03
height<- rnorm(10000, 170, 13)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
summary(list(s1,s2))
lapply(list(s1,s2), summary)
lapply(list(s1,s2), fivenum)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
hist(list(s1,s2)
)
lapply(list(s1,s2), hist)
(100-183)/24
(110-183)/24
(120-183)/24
(115-183)/24
(115-145)/25
(195-183)/24
qnorm(.5, lower.tail = F)
pnorm(.5, lower.tail = F)
(195-145)/25
pnorm(2, lower.tail = F)
R.home()
system("echo $HOME")
q()
.000023
y<-rnorm(100)
edit(y)
q(save = F)
?@
?'@'
install.packages("MCMCglmm")
sd(c(1,3,4,5,7))
sd(c(1,3,4,5,7))*sqrt(4/5)
?sd
mean(1:5)
mean(c(2,1,4,6,5))
sd(1:5)*sqrt(4/5)
sd(1:5)
sd(c(2,1,4,6,5))*sqrt(4/5)
mean(c(6,0,-2,0,6))
mean(c(-4,-2,0,2,4))
mean((x<-c(-4,-2,0,2,4)))
mean((y<-c(6,0,-2,0,6)))
cor(x,y)
sd(x)*sqrt(4/5)
sd(y)*sqrt(4/5)
mean((x/2.83)*(y-2)/3.35)
mean(x*y)
qnorm(.05)*.5
pnorm(qnorm(.05)*.5)
pnorm(qnorm(.8)*.5)
pnorm(qnorm(.5)*.5)
4/2.7*.25*2.5+63
-4/2.7*.25*2.5+63
sqrt(1-.6^2)*15
plot_power <- function(power_mat){
na_i <- n_p > 0
props <- seq(0,100,by=20)[na_i]
sds <- 2*sqrt(.25/n_p[na_i])
pdf("power_plot.pdf")
errbar(props, (y<-power_mat[na_i,1]), y+sds, y-sds, type = "b", pch=16, col='red', errbar.col = 'red', ylim = c(0,1), cap = .03,
ylab = "Power", xlab = "Proportion of variance on logit scale due to polygenic effects/covariates", xaxt = "n" )
for(i in 2:4){
errbar(props, (y<-power_mat[na_i,i]), y+sds, y-sds, type = "b",add=T, cap = .03,pch = c(15,17,18)[i-1], col=c('blue','lightgreen','purple')[i-1], errbar.col = c('blue','lightgreen','purple')[i-1])
}
axis(1, at = props, label = c("0/100", "20/80","40/60","60/40","80/20","100/0")[na_i])
legend('topright', horiz = F, legend = c('MCMCglmm', 'GMMAT','CARAT','CERAMIC'), pch = c(16,15,17,18), col = c('red','blue','lightgreen','purple'), cex=1.4, bty="n")
dev.off()
}
pvals_analysis <- function(p_vals, al){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result$Err_rate[alpha==al]
}
draw_pval <- function(ind, p_vals_list, meth_list, percent){
p_vals <- p_vals_list[[ind]]
method <- meth_list[ind]
n <- length(p_vals)
uni2 <- rank(p_vals, ties.method='max'); names(uni2)=c()
plot(-log10(uni2/(n+1)),-log10(p_vals), type="n", ylab=expression('Observed (-log'[10]*' p-value)'), xlab=expression('Expected (-log'[10]*' p-value)'))
a=1:n
high <- qbeta(0.025, a, rev(a))
low <- qbeta(0.975, a, rev(a))
polygon(-log10(c(a/n,rev(a/n))), -log10(c(high, rev(low))), col ='gray', border = NA)
points(-log10(uni2/(n+1)),-log10(p_vals), pch=16,cex=.3)
title(expression(bold('Plot of observed vs. expected -log'[10]*' p-values')),line=2)
title(paste('With', method), line=.5)
abline(a=0,b=1,col="red")
}
n_p=rep(0, n_M)
method_used = c('MCMCglmm', 'GMMAT','CARAT','CERAMIC')
power_mat <- matrix(NA, n_M, 4)
type1err <- matrix(NA, n_M, 4, dimnames = list(NULL, method_used))
for(k in 1:n_M){
assign(paste0('p_vals',k,'_t1err'), vector("list", 4)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", 4)) # List for 4 methods
}
for(i in 1:4){
for(j in 1:n_rep){
for(k in 1:n_M){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',k,'_t1err[[',i,']] <- append(p_vals',k,'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',k,'_pow[[',i,']] <- append(p_vals',k,'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[k] = n_p[k] + 1; }
}
}
}
level <- .05
# Power
for(k in 1:n_M){
eval(parse(text=paste0('power_mat[',k,',] <- unlist(lapply(p_vals',k,'_pow, function(x) mean(x<level)))')))
}
power_mat
res[[6]][[1]]
props <- seq(0,100,by=20)
n_pvals <- NULL
for(k in 1:n_M){
eval(parse(text=paste0('type1err[',k,',] <- unlist(lapply(p_vals',k,'_t1err, pvals_analysis, al = .05))')))
eval(parse(text=paste0('n_pvals[',k,'] <- length(p_vals',k,'_t1err[[1]])')))
}
write.table(type1err, row.names=FALSE, quote=FALSE); t(sapply(n_pvals, function(x).05 + c(-1,1)*2*sqrt(.05*(1-.05)/x)))
png("t1err_plot%d.png", width = 12, height = 9, units = 'in', res=200)
par(mfrow = c(2,2))
for(k in 1:n_M){
eval(parse(text=paste0('lapply(1:4, draw_pval, p_vals',k,'_t1err, method_used)')))
title(paste('Polygenic effect / Covariates:',props[k],'/',100-props[k]), outer=TRUE, cex=1.1, line = -1.5)
}
dev.off()
library(Hmisc)
plot_power(power_mat)
p_vals6_t1err
str(p_vals6_t1err)
summary(p_vals6_t1err[[1]])
hist(p_vals6_t1err[[1]])
min(p_vals6_t1err[[1]])
head(sort(p_vals6_t1err[[1]]))
head(sort(p_vals6_t1err[[2]]))
require(MCMCglmm)
?MCMCglmm
?rbeta
edit(rbeta)
edit(rbeta)
library(Matrix)
?Matrix::`dgCMatrix-class`
?as
?cor
?cov
edit(cov)
sum(c(1,2),c(5,10))
sum(as.vector(c(1,2)),as.vector(c(5,10)))
c(1,2)+c(5,10))
c(1,2)+c(5,10)
?scale
?dcauchy
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With related individuals + missing G/Type 1 error + power/old settings/.RData")
res
sqrt(.05*.95/5000)
?predcit.MCMCglmm
?MCMCglmm::predict.MCMCglmm
edit(predict.MCMCglmm)
library(MCMCglmm)
edit(predict.MCMCglmm)
edit(predict.MCMCglmm)
?@
?'@'
n_M
n_M@
n_M
slot(Prec,x)
slot(Prec,n_M)
slot(Prec)
slot(Prec,"attr")
slotNames(Prec)
Prec@i
Prec@x
Prec$x
str(Prec)
str(Prec@x)
dim(Prec@x)
edit(predict.MCMCglmm)
update.packages("MCMCglmm")
edit(MCMCglmm::predict.MCMCglmm())
edit(MCMCglmm::predict.MCMCglmm
)
predict.MCMCglmm
update.packages("MCMCglmm")
sqrt(.25*.75*500)
sqrt(.25*.75)
sqrt(.25*.75/500)
sqrt(.25*.75/500)*100
sqrt(.25*.75/1000)*100
sqrt(.25*.75/2000)*100
sqrt(.25*.75*2000)/2000*100
.25*2000
sqrt(.25*.75*2000)
172*2
414+344+242
sqrt(1-.6^2)*15
(80-65)/20*.6
.45*15+75
(85-65)/20*.6
.6*15+75
sqrt(1/10*9/10)*sqrt(1000)
1/10*2000
sqrt(3/10*7/10)*sqrt(1000)
pnorm(310,300,14.49,lower.tail = F)
pnorm(110,100,9.49,lower.tail = F)
100
10/6
12/6
sqrt(2/6*4/6)*6*sqrt(100)
sd(rep(c(0,6),c(4,2))*sqrt(100)
)
sd(rep(c(0,6),c(4,2)))*sqrt(100)
sd(rep(c(0,6),c(4,2)))*sqrt(100*5/6)
2*100
sqrt(2/6*4/6)*6*sqrt(100)
sqrt(2/6*4/6)*sqrt(100)
2/6
2/6*100
pnorm(35,2/6*100,4.714045,lower.tail = F)
100-1/6*10
1/6*100
100-14-10-17
2/6*100
100-14-10-17-40
1/6*100
sqrt(1/6*5/6)*sqrt(100)
(19-16.67)/3.72678
.4
2/6
sqrt(2/6*4/6)/sqrt(100)
sqrt(2/6*4/6)/sqrt(100)*100
(40-33.33)/4.71
sd(c(-4,-3,-1,0,6,6))*sqrt(5/6)
mean(c(-4,-3,-1,0,6,6))
4/sqrt(100)
mean(c(-4,-3,-1,0,6,6))*100
4*sqrt(100)
mean(c(-4,-3,-1,0,6,6))*200
4*sqrt(200)
pnorm(120,133,56.6,lower.tail = F)
54/500
sqrt(0.108*(1-0.108)/500)
.108+c(-1,1)*2*sqrt(0.108*(1-0.108)/500)
setwd("C:\Users\JOELLE\Google Drive\Reasearch Mary Sara _ SAMSUNG\Permutation based methods\Binary trait\Results\MCMCglmm\Project - assoc mapping w binary traits\With peds + missing G\effect of asc")
getwd()
setwd("./Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/effect of asc/")
load(".RData")
M
n_rep
index <- ceiling(M[,1]*10+1)[sapply(res,length) > 0]
index
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
target_v[j] <- res[k][j][[1]]
est_v[j] <- res[k][j][[2]]
}
}
}
target_v <- est_v <- NULL
index <- ceiling(M[,1]*10+1)[sapply(res,length) > 0]
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
target_v[j] <- res[k][j][[1]]
est_v[j] <- res[k][j][[2]]
}
}
}
res[[1]][[1]]
res[[1]][[1]][[1]]
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
target_v<- append(target_v, res[k][j][[1]])
est_v<- append(est_v, res[k][j][[2]])
}
}
}
k
j
length(res)
sapply(res,length) > 0
res[[1]][[200]]
n_rep
length(index)
n_rep
target_v <- est_v <- NULL
index <- ceiling(M[,1]*10+1)[sapply(res,length) > 0]
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
target_v<- append(target_v, res[k][j][[1]])
est_v<- append(est_v, res[k][j][[2]])
}
}
}
res[1][2]
target_v <- est_v <- NULL
index <- ceiling(M[,1]*10+1)[sapply(res,length) > 0]
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
target_v<- append(target_v, res[[k]][[j]][[1]])
est_v<- append(est_v, res[[k]][[j]][[2]])
}
}
}
plot(target_v, est_v)
boxplot(list(target_v, est_v))
plot(target_v, est_v, ylim=c(0,5))
plot(target_v, est_v, ylim=c(0,1))
boxplot(list(target_v, est_v), ylim=c(0,5))
df<-data.frame(x=rnorm(22), y=rnorm(22))
crossprod(phi,df)
for(x in df_u){str(crossprod(Prec,x))
}
for(x in df){str(crossprod(Prec,x))}
for(x in df){str(crossprod(phi_inv,x))}
for(x in df){boxplot(crossprod(phi_inv,x))}
