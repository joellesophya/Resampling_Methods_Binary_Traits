x=kinship2::pedigree(id = ped1$ind,dadid = ped1$fa,momid = ped1$mo,sex = ped1$sex)
plot(x)
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-09-2016/Project 4 - VTnocovs - Cauchy 10 - 50k Yp - 200Yr - 5pct thresh - w covs_unobsG/tu 20&40 at 20%/A.RData")
pvals_analysis(p_valsMCMC[[1]])
est_varMCMC
mean(est_varMCMC[[1]])
median(est_varMCMC[[1]])
.2*1.2
sd(est_varMCMC[[1]])
sd(est_varMCMC[[1]])/length(est_varMCMC[[1]])
sd(est_varMCMC[[1]])/sqrt(length(est_varMCMC[[1]]))
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-09-2016/Project 4 - VTnocovs - Cauchy 10 - 50k Yp - 200Yr - 5pct thresh - w covs_unobsG/tu 20&40 at 20%/B.RData")
pvals_analysis(p_valsMCMC[[2]])
sd(est_varMCMC[[2]])/sqrt(length(est_varMCMC[[2]]))
mean(est_varMCMC[[2]])
median(est_varMCMC[[2]])
.4*1.2
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-09-2016/Project 4 - VTnocovs - Cauchy 10 - 50k Yp - 200Yr - 5pct thresh - w covs_unobsG/tu 20&40 at 20%/A.RData")
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-09-2016/Project 4 - VTnocovs - Cauchy 10 - 50k Yp - 200Yr - 5pct thresh - w covs_unobsG/tu 60&80 at 20%/A.RData")
pvals_analysis(p_valsMCMC[[1]])
pvals_analysis(p_valsMCMC[[2]])
mean(est_varMCMC[[2]])
median(est_varMCMC[[2]])
sd(est_varMCMC[[2]])/sqrt(length(est_varMCMC[[2]]))
M
.8*1.3
.6*1.3
length(est_varMCMC[[2]])
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-09-2016/Project 4 - VTnocovs - Cauchy 10 - 50k Yp - 200Yr - 5pct thresh - w covs_unobsG/tu 60&80 at 20%/B.RData")
mean(est_varMCMC[[1]])
median(est_varMCMC[[1]])
sd(est_varMCMC[[1]])/sqrt(length(est_varMCMC[[1]]))
hist(est_varMCMC[[1]])
ls()
str(p_valsMCMC)
res[[1]]
lapply(res[[1]],length)
sapply(res[[1]],length)
sapply(res[[1]],function(x)x>0)
sapply(res[[1]],function(x)mean(x>0))
res[[1]][[115]]
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-09-2016/Project 4 - VTnocovs - Cauchy 10 - 50k Yp - 200Yr - 5pct thresh - w covs_unobsG/tu 20-100 at 40%/.RData")
pdf("Summaries of pvals_5pct.pdf")
for(i in 1:n_M) {
print(paste("Proportion of add_var : ", M[i,1]*100, "%", sep = ""))
summary(p_valsMCMC[[i]])
hist(p_valsMCMC[[i]], main="Using MCMCglmm estimates",freq = F, breaks=100, xlab="p-value")
title(bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"] ="~.(M[i,1]*100)*"%"),line=.7, cex.main = .9)
title(bquote("n ="~.(length(p_valsMCMC[[i]]))),line=-1, cex.main = .7)
abline(h=1,col="red")
}
boxplot(est_varMCMC, xaxt="n", ylab="Additive variance estimates",
xlab=bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"]   (in %)"),
main = "Variance estimates over 200 Y realizations",
col = rep(c("turquoise","red"), each = n_M), ylim = c(0,9))
axis(1, at=1:n_M, labels=M[,1]*100)
abline(h= M[,1]*M[,2], col= rep("black",n_M), lty =2)
dev.off()
pdf("pvals_5pct.pdf")
for(i in 1:n_M) {
print(paste("Proportion of add_var : ", M[i,1]*100, "%", sep = ""))
summary(p_valsMCMC[[i]])
hist(p_valsMCMC[[i]], main="Using MCMCglmm estimates",freq = F, breaks=100, xlab="p-value")
title(bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"] ="~.(M[i,1]*100)*"%"),line=.7, cex.main = .9)
title(bquote("n ="~.(length(p_valsMCMC[[i]]))),line=-1, cex.main = .7)
abline(h=1,col="red")
}
boxplot(est_varMCMC, xaxt="n", ylab="Additive variance estimates",
xlab=bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"]   (in %)"),
main = "Variance estimates over 200 Y realizations",
col = rep(c("turquoise","red"), each = n_M), ylim = c(0,9))
axis(1, at=1:n_M, labels=M[,1]*100)
abline(h= M[,1]*M[,2], col= rep("black",n_M), lty =2)
dev.off()
pdf("pvals_5pct.pdf")
for(i in 1:n_M) {
print(paste("Proportion of add_var : ", M[i,1]*100, "%", sep = ""))
summary(p_valsMCMC[[i]])
hist(p_valsMCMC[[i]], main="Using MCMCglmm estimates",freq = F, breaks=100, xlab="p-value")
title(bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"] ="~.(M[i,1]*100)*"%"),line=.7, cex.main = .9)
title(bquote("n ="~.(length(p_valsMCMC[[i]]))),line=-1, cex.main = .7)
abline(h=1,col="red")
}
boxplot(est_varMCMC, xaxt="n", ylab="Additive variance estimates",
xlab=bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"]   (in %)"),
main = "Variance estimates over 200 Y realizations",
col = rep(c("turquoise","red"), each = n_M), ylim = c(0,15))
axis(1, at=1:n_M, labels=M[,1]*100)
abline(h= M[,1]*M[,2], col= rep("black",n_M), lty =2)
dev.off()
lapply(p_valsMCMC, pvals_analysis)
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-05-2016/Project 2 - WS - Cauchy 10 - 50k Yp - 200Yr - 1pct thresh - w covs_unobsG/.RData")
p_valsMCMC[[1]][1:2]
p_valsMCMC[[2]][1:2]
p_valsMCMC[[1]][1:20]
summary(p_valsMCMC[[1]])
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-09-2016/Project 4 - VTnocovs - Cauchy 10 - 50k Yp - 200Yr - 5pct thresh - w covs_unobsG/tu 0-100 at 60%/.RData")
pdf("pvals_5pct.pdf")
for(i in 1:n_M) {
print(paste("Proportion of add_var : ", M[i,1]*100, "%", sep = ""))
summary(p_valsMCMC[[i]])
hist(p_valsMCMC[[i]], main="Using MCMCglmm estimates",freq = F, breaks=100, xlab="p-value")
title(bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"] ="~.(M[i,1]*100)*"%"),line=.7, cex.main = .9)
title(bquote("n ="~.(length(p_valsMCMC[[i]]))),line=-1, cex.main = .7)
abline(h=1,col="red")
}
boxplot(est_varMCMC, xaxt="n", ylab="Additive variance estimates",
xlab=bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"]   (in %)"),
main = "Variance estimates over 200 Y realizations",
col = rep(c("turquoise","red"), each = n_M), ylim = c(0,25))
axis(1, at=1:n_M, labels=M[,1]*100)
abline(h= M[,1]*M[,2], col= rep("black",n_M), lty =2)
dev.off()
sum(1:990)
sum(1:990*sample(0:1,990))
sum(1:990*sample(0:1,990, replace = T))
sum(1:990*sample(0:1,990, replace = T))
sum(1:990*sample(0:1,990, replace = T))
sum(1:990*sample(0:1,990, replace = T))
sum(1:990*sample(0:1,990, replace = T))
sum(1:990*sample(0:1,990, replace = T))
sum(1:990*sample(0:1,990, replace = T, prob = c(.7,.3)))
sum(1:990*sample(0:1,990, replace = T, prob = c(.7,.3)))
sum(1:990*sample(0:1,990, replace = T, prob = c(.7,.3)))
sum(1:990*sample(0:1,990, replace = T, prob = c(.7,.3)))
sum(1:990*sample(0:1,990, replace = T, prob = c(.7,.3)))
sum(1:990*sample(0:1,990, replace = T, prob = c(.7,.3)))
sum(1:990*sample(0:1,990, replace = T, prob = c(.7,.3)))
qnorm(1-.01/2)
qnorm(1-.05/2)
pnorm(-3)
pnorm(-1.96)
pnorm(-3)*2
1-pnorm(-3)*2
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-05-2016/Project 2 - WS - Cauchy 10 - 50k Yp - 200Yr - 5pct thresh - w covs_unobsG/0-100 at 20%/B.RData")
p_valsMCMC <- vector("list", n_M) # List of size n_M
est_varMCMC <- vector("list", n_M)
m <- length(res[[1]][[1]]) # Number of pvals + est add var
for(i in 1:n_M) {
for (j in 1:n_rep){
if (!any(res[[i]][[j]][-m] < 0)) p_valsMCMC[[i]] <- append(p_valsMCMC[[i]], res[[i]][[j]][-m])
est_varMCMC[[i]] <- append(est_varMCMC[[i]], res[[i]][[j]][m])
}
}
pdf("pvals_WS_5pct.pdf")
for(i in 1:n_M) {
print(paste("Proportion of add_var : ", M[i,1]*100, "%", sep = ""))
summary(p_valsMCMC[[i]])
hist(p_valsMCMC[[i]], main="Using MCMCglmm estimates",freq = F, breaks=100, xlab="p-value")
title(bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"] ="~.(M[i,1]*100)*"%"),line=.7, cex.main = .9)
title(bquote("n ="~.(length(p_valsMCMC[[i]]))),line=-1, cex.main = .7)
abline(h=1,col="red")
}
boxplot(est_varMCMC, xaxt="n", ylab="Additive variance estimates",
xlab=bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"]   (in %)"),
main = "Variance estimates over 200 Y realizations",
col = rep(c("turquoise","red"), each = n_M))
axis(1, at=1:n_M, labels=M[,1]*100)
abline(h= M[,1]*M[,2], col= rep("black",n_M), lty =2)
dev.off()
pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-05-2016/Project 2 - WS - Cauchy 10 - 50k Yp - 200Yr - 5pct thresh - w covs_unobsG/1 pct thresh/.RData")
p_valsMCMC <- vector("list", n_M) # List of size n_M
est_varMCMC <- vector("list", n_M)
m <- length(res[[1]][[1]]) # Number of pvals + est add var
for(i in 1:n_M) {
for (j in 1:n_rep){
if (!any(res[[i]][[j]][-m] < 0)) p_valsMCMC[[i]] <- append(p_valsMCMC[[i]], res[[i]][[j]][-m])
est_varMCMC[[i]] <- append(est_varMCMC[[i]], res[[i]][[j]][m])
}
}
pdf("pvals_WS_1pct.pdf")
for(i in 1:n_M) {
print(paste("Proportion of add_var : ", M[i,1]*100, "%", sep = ""))
summary(p_valsMCMC[[i]])
hist(p_valsMCMC[[i]], main="Using MCMCglmm estimates",freq = F, breaks=100, xlab="p-value")
title(bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"] ="~.(M[i,1]*100)*"%"),line=.7, cex.main = .9)
title(bquote("n ="~.(length(p_valsMCMC[[i]]))),line=-1, cex.main = .7)
abline(h=1,col="red")
}
boxplot(est_varMCMC, xaxt="n", ylab="Additive variance estimates",
xlab=bquote(sigma[a]^2 ~ "/ [Var(X"*beta*") +"~ sigma[a]^2~"]   (in %)"),
main = "Variance estimates over 200 Y realizations",
col = rep(c("turquoise","red"), each = n_M))
axis(1, at=1:n_M, labels=M[,1]*100)
abline(h= M[,1]*M[,2], col= rep("black",n_M), lty =2)
dev.off()
pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
?COS
?cos
cos(18*pi/180)
76*sin(18*pi/180)
cos(18*pi/180)*76
cos(52*pi/180)*121
sin(52*pi/180)*121
23.485-146.775
sqrt(146.775^2+123.29^2)
a <- pi/180
75*cos(22*a)+117*cos(55*a)
75*sin(22*a)-117*sin(55*a)
75*sin(22*a)-117*sin((360-55)*a)
75*sin(22*a)+117*sin((360-55)*a)
sin(305*a)*117
75*sin(22*a)
28.1-95.8
69.5 +67.1
28.1+- 95.8
tanh(67.74529/136.6472)
?tan
atan(67.74529/136.6472)
atan(76.7/ 136.6 )
atan(67.74529/136.6472*a)
atan(67.74529/136.6472/a)
b=67.74529/136.6472
b
tanh(b)
atan(b)
atan(2)
b
tan(26.1*a)
tan(26.4*a)
arctan(.496)
atan(.496)
atan(67.6/136.6)
atan(67.6/136.6)/a
atan(b)/a
sin(305*a)
-sin(55*a)
121/76
121-76
72.3+74.5
76*cos(18*a)
76*sin(18*a)
121*sin(52*a)
121*cos(52*a)
72.3+74.5
23.5-95.3
23.485-95.349
sqrt(146.775^2+71.864^2)
23.5-95.3
sqrt(146.8^2+71.8^2)
atan(71.8/146.8)/a
23.5+95.3
sqrt(9.8*117.348/sin(2*27*pi/180))
x<-NULL
X = append(X, c(2:5))
x = append(x, c(2:5))
x
library(rmvnorm)
5 %in% 6:8
7 %in% 6:8
`+`(x,1)
x
libary(mvtnorm)
library(mvtnorm)
?rmvnorm
ep(x)
rep(x)
rmvnorm(1)
rmvnorm(1, mean = 0, sigma = diag(4))
rmvnorm(1, mean = rep(0,4), sigma = diag(4))
class(rmvnorm(1, mean = rep(0,4), sigma = diag(4)))
class(c(rmvnorm(1, mean = rep(0,4), sigma = diag(4))))
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-09-2016/Project 2 - WS - Cauchy 10 - 50k Yp - 200Yr - w covs_unobsG/1pct thresh/at 40%/B.RData")
lapply(p_valsMCMC, pvals_analysis)
pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
ls()
p_valsMCMC <- vector("list", n_M) # List of size n_M
est_varMCMC <- vector("list", n_M)
m <- length(res[[1]][[1]]) # Number of pvals + est add var
for(i in 1:n_M) {
for (j in 1:n_rep){
if (!any(res[[i]][[j]][-m] < 0)) p_valsMCMC[[i]] <- append(p_valsMCMC[[i]], res[[i]][[j]][-m])
est_varMCMC[[i]] <- append(est_varMCMC[[i]], res[[i]][[j]][m])
}
}
lapply(p_valsMCMC, pvals_analysis)
M = rbind(c(0,1.1))
n_M = dim(M)[1]
G1<-1:10
write.table(c("SNP1",G1),'geno.txt',row.names=FALSE, col.names=FALSE, sep='\t')
write(c("SNP1",G1),'geno.txt',row.names=FALSE, col.names=FALSE, sep='\t')
write(c("SNP1",G1),'geno.txt', sep='\t', ncolumns = 11)
library(GMMAT)
1078.94-925
start <- 1078.94-925
start + 50 + 120
start + 50 + 120 - 50 - 50 - 23
start + 50 + 120 - 50 - 50 - 23 - 1000
start + 50 + 120 - 50 - 50 - 23 - 1000 - 35
start + 50 + 120 - 50 - 50 - 23 - 1000 - 35 + 1035
176.63*1.03
height<- rnorm(10000, 170, 13)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
summary(list(s1,s2))
lapply(list(s1,s2), summary)
lapply(list(s1,s2), fivenum)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
hist(list(s1,s2)
)
lapply(list(s1,s2), hist)
(100-183)/24
(110-183)/24
(120-183)/24
(115-183)/24
(115-145)/25
(195-183)/24
qnorm(.5, lower.tail = F)
pnorm(.5, lower.tail = F)
(195-145)/25
pnorm(2, lower.tail = F)
R.home()
system("echo $HOME")
q()
.000023
y<-rnorm(100)
edit(y)
q(save = F)
?@
?'@'
install.packages("MCMCglmm")
?glm
x<- rnorm(1000)
U <- rnorm(1000,4,2)
Y <- 4*x + U
Y <- plogis(Y)
Y <- rbinom(1000, 1 , Y)
glm(Y~X + offset(U),family = "binomial", link='logit')
glm(Y~x + offset(U),family = "binomial", link='logit')
?binomial
glm(Y~x + offset(U),family = binomial(link = "logit"))
glm(Y~x + U,family = binomial(link = "logit"))
m1_form <- Y~x + offset(U)
model.offset(m1_form)
m1_form <- model.frame(Y~x + offset(U))
model.offset(m1_form)
identical(model.offset(m1_form),u)
head(model.offset(m1_form))
u
head(model.offset(m1_form))
heaed(u)
head(u)
identical(model.offset(m1_form),U)
ls()
glm(Y~x + U,family = binomial(link = "logit"))
glm(Y~x + offset(U),family = binomial(link = "logit"))
glm(Y~x + offset(U),family = binomial(link = "logit"))$res
summary(glm(Y~x + offset(U),family = binomial(link = "logit"))$res)
summary(Y)
summary(resid(glm(Y~x + offset(U),family = binomial(link = "logit"))))
summary(resid(glm(Y~x + offset(U),family = binomial(link = "logit")), type = "response"))
summary(X*resid(glm(Y~x + offset(U),family = binomial(link = "logit")), type = "response"))
summary(x*resid(glm(Y~x + offset(U),family = binomial(link = "logit")), type = "response"))
mean(x*resid(glm(Y~x + offset(U),family = binomial(link = "logit")), type = "response"))
setwd("Results/MCMCglmm/Project - assoc mapping w binary traits/With related individuals + missing G/")
load(".RData")
length(res)
length(res[[1]])
length(res[[2]])
n_p=rep(0, 6)
method_used = c('MCMCglmm', 'GMMAT','CARAT','CERAMIC')
power_mat = matrix(NA, 6, 4)
type1err <- matrix(NA, 6, 4, dimnames = list(NULL, method_used))
index <- 1
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", 4)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", 4)) # List for 4 methods
}
for(i in 1:4){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[index[k]] = n_p[index[k]] + 1; }
}
}
}
ls()
str(p_vals1_pow)
str(p_vals1_t1err)
index = 1
level = .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',index[k],',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
plot_power(power_mat)
# Type 1 Error
props <- seq(0,100,by=20)
for(k in 1:length(index)){
eval(parse(text=paste0('type1err[',index[k],',] <- unlist(lapply(p_vals',index[k],'_t1err, pvals_analysis, al = .05))')))
}
write.table(type1err, row.names=FALSE, quote=FALSE); .05+c(-1,1)*2*sqrt(.05*(1-.05)/5e4)
png("type_1_error_plots%01d.png", width = 12, height = 9, units = 'in', res=200)
par(mfrow = c(2,2))
for(k in 1:length(index)){
eval(parse(text=paste0('lapply(1:4, draw_pval, p_vals',index[k],'_t1err, method_used)')))
title(paste('Polygenic effect / Covariates:',props[index[k]],'/',100-props[index[k]]), outer=TRUE, cex=1.1, line = -1.5)
}
dev.off()
plot_power <- function(power_mat){
na_i <- n_p > 0
props <- seq(0,100,by=20)[na_i]
sds <- 2*sqrt(.25/n_p[na_i])
pdf("power_plot.pdf")
errbar(props, (y<-power_mat[na_i,1]), y+sds, y-sds, type = "b", pch=16, col='red', errbar.col = 'red', ylim = c(0,1), cap = .03,
ylab = "Power", xlab = "Proportion of variance on logit scale due to polygenic effects/covariates", xaxt = "n" )
for(i in 2:4){
errbar(props, (y<-power_mat[na_i,i]), y+sds, y-sds, type = "b",add=T, cap = .03,pch = c(15,17,18)[i-1], col=c('blue','lightgreen','purple')[i-1], errbar.col = c('blue','lightgreen','purple')[i-1])
}
axis(1, at = props, label = c("0/100", "20/80","40/60","60/40","80/20","100/0")[na_i])
legend('topright', horiz = F, legend = c('MCMCglmm', 'GMMAT','CARAT','CERAMIC'), pch = c(16,15,17,18), col = c('red','blue','lightgreen','purple'), cex=1.4, bty="n")
dev.off()
}
pvals_analysis <- function(p_vals, al){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result$Err_rate[alpha==al]
}
draw_pval <- function(ind, p_vals_list, meth_list, percent){
p_vals <- p_vals_list[[ind]]
method <- meth_list[ind]
n <- length(p_vals)
uni2 <- rank(p_vals, ties.method='max'); names(uni2)=c()
plot(-log10(uni2/(n+1)),-log10(p_vals), type="n", ylab=expression('Observed (-log'[10]*' p-value)'), xlab=expression('Expected (-log'[10]*' p-value)'))
a=1:n
high <- qbeta(0.025, a, rev(a))
low <- qbeta(0.975, a, rev(a))
polygon(-log10(c(a/n,rev(a/n))), -log10(c(high, rev(low))), col ='gray', border = NA)
points(-log10(uni2/(n+1)),-log10(p_vals), pch=16,cex=.3)
title(expression(bold('Plot of observed vs. expected -log'[10]*' p-values')),line=2)
title(paste('With', method), line=.5)
abline(a=0,b=1,col="red")
}
index = 1
level = .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',index[k],',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
plot_power(power_mat)
# Type 1 Error
props <- seq(0,100,by=20)
for(k in 1:length(index)){
eval(parse(text=paste0('type1err[',index[k],',] <- unlist(lapply(p_vals',index[k],'_t1err, pvals_analysis, al = .05))')))
}
write.table(type1err, row.names=FALSE, quote=FALSE); .05+c(-1,1)*2*sqrt(.05*(1-.05)/5e4)
png("type_1_error_plots%01d.png", width = 12, height = 9, units = 'in', res=200)
par(mfrow = c(2,2))
for(k in 1:length(index)){
eval(parse(text=paste0('lapply(1:4, draw_pval, p_vals',index[k],'_t1err, method_used)')))
title(paste('Polygenic effect / Covariates:',props[index[k]],'/',100-props[index[k]]), outer=TRUE, cex=1.1, line = -1.5)
}
dev.off()
