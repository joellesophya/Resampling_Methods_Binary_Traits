pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Type 1 error + power/w post. mean of u/Eu/.RData")
setwd("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Type 1 error + power/w post. mean of u/Eu/")
ls()
n_p <-integer(length(index <- ceiling(M[,1]*10+1)[sapply(res,length) > 0]))
props <- seq(0,100,10)[index]
n_meth <- length( (method_used = c('MCMCglmm_mean','MCMCglmm_mode','MCMCglmm_mean_1M_iter','MCMCglmm_mode_1M_iter', 'CERAMIC')) )
power_mat = matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used))
# type1err <- matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used))
n_pvals <- NULL
for(k in index){
# assign(paste0('p_vals',k,'_t1err'), vector("list", n_meth)) # List for the methods
assign(paste0('p_vals',k,'_pow'), vector("list", n_meth)) # List for the methods
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
# eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[k] = n_p[k] + 1; }
}
}
}
index
p_vals5_pow
n_p <-integer(length(index <- ceiling(M[,1]*10+1)[sapply(res,length) > 0]))
props <- seq(0,100,10)[index]
n_meth <- length( (method_used = c('MCMCglmm_mean','MCMCglmm_mode','MCMCglmm_mean_1M_iter','MCMCglmm_mode_1M_iter', 'CERAMIC')) )
power_mat = matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used))
# type1err <- matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used))
n_pvals <- NULL
for(k in index){
# assign(paste0('p_vals',k,'_t1err'), vector("list", n_meth)) # List for the methods
assign(paste0('p_vals',k,'_pow'), vector("list", n_meth)) # List for the methods
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
# eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
if(any(is.na(res[[k]][[j]]$Po)){
res[[k]][[j]]$Po[3:4] <- res[[k]][[j]]$Po[1:2]
}
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[k] = n_p[k] + 1; }
}
}
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
# eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
if(any(is.na(res[[k]][[j]]$Po))){
res[[k]][[j]]$Po[3:4] <- res[[k]][[j]]$Po[1:2]
}
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[k] = n_p[k] + 1; }
}
}
}
level <- .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',k,',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
Tu_vals <- props/100
plot_power(na.omit(power_mat), Tu_vals, method_used)
seq(ncol(power_mat))
colors()
rainbow(3)
?rainbow
plot(1:6, col=rainbow(6))
power_mat
plot_power <- function(power_mat, props, meth_list){
sds <- 2*sqrt(.25 / n_p)
n_method <- length(meth_list)
col_vec <- rainbow(n_method)
pch_vec <- 14 + seq(n_method)
pdf("power_plot.pdf")
errbar(props, (y<-power_mat[,1]), y+sds, y-sds, type = "b", pch=pch_vec[1], col=col_vec[1], errbar.col = col_vec[1], ylim = c(0,1), cap = .03,
ylab = "Power", xlab = "Proportion of variance on logit scale due to polygenic effects/covariates", xaxt = "n" )
for(i in 2:n_method){
errbar(props, (y<-power_mat[,i]), y+sds, y-sds, type = "b",add=T, cap = .03,pch = pch_vec[i], col= col_vec[i], errbar.col = col_vec[i])
}
axis(1, at = props, label = paste(props*100, (1-props)*100, sep = "/") )
legend('topright', horiz = F, legend = meth_list, pch = pch_vec , col = col_vec, cex=1.4, bty="n")
dev.off()
}
n_p <-integer(length(index <- ceiling(M[,1]*10+1)[sapply(res,length) > 0]))
props <- seq(0,100,10)[index]
n_meth <- length( (method_used = c('MCMCglmm_mean','MCMCglmm_mode','MCMCglmm_mean_1M_iter','MCMCglmm_mode_1M_iter', 'CERAMIC')) )
power_mat = matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used))
# type1err <- matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used))
n_pvals <- NULL
for(k in index){
# assign(paste0('p_vals',k,'_t1err'), vector("list", n_meth)) # List for the methods
assign(paste0('p_vals',k,'_pow'), vector("list", n_meth)) # List for the methods
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
# eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
if(any(is.na(res[[k]][[j]]$Po)){
res[[k]][[j]]$Po[3:4] <- res[[k]][[j]]$Po[1:2]
}
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[k] = n_p[k] + 1; }
}
}
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
# eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
if(any(is.na(res[[k]][[j]]$Po))){
res[[k]][[j]]$Po[3:4] <- res[[k]][[j]]$Po[1:2]
}
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[k] = n_p[k] + 1; }
}
}
}
level <- .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',k,',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
Tu_vals <- props/100
plot_power(na.omit(power_mat), Tu_vals, method_used)
power_mat
n_p
sqrt(.5*.5/150)
sqrt(sqrt(.5*.5/150)^2*2)
sqrt(sqrt(.41*.59/150)^2*2)
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Qs/eff.siz/Wasc_eff_siz.RData")
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Qs/target-est add_v/.RData")
setwd("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Qs/target-est add_v/")
ls()
target_v <- est_v_mean <- est_v_mode <- effS <- list(Tu1=NULL, Tu2=NULL)
n <- length(index <- ceiling(M[,1]*10+1)[sapply(res,length) > 0])
for(j in 1:n_rep){
for(k in 1:n){
target_v[[k]] <- append(target_v[[k]], res[[k]][[j]][[1]])
est_v_mean[[k]] <- append(est_v_mean[[k]], res[[k]][[j]][[2]])
est_v_mode[[k]] <- append(est_v_mode[[k]], res[[k]][[j]][[3]])
effS[[k]] <- append(effS[[k]], res[[k]][[j]][[4]])
}
}
pdf("results_out_red.pdf"); par(mfrow=c(2,2))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mean[[i]], ylim=c(0,5), main = paste("true vs mean est at Tu=", M[i,1])))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mode[[i]], ylim=c(0,5),main = paste("true vs mode est at Tu=", M[i,1])))
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mean[[i]], ylim=c(0,5),main = paste("Effective size vs mean est at Tu=", M[i,1])); abline(h = range(target_v[[i]]), col="red" )})
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mode[[i]], ylim=c(0,5),main = paste("Effective size vs mode est at Tu=", M[i,1])); abline(h = range(target_v[[i]]), col="red" )})
dev.off()
pdf("results_out1.pdf"); par(mfrow=c(2,2))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mean[[i]], ylim=c(0,5), main = paste("true vs mean est at Tu=", M[i,1])))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mode[[i]], ylim=c(0,5),main = paste("true vs mode est at Tu=", M[i,1])))
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mean[[i]],main = paste("Effective size vs mean est at Tu=", M[i,1])); abline(h = range(target_v[[i]]), col="red" )})
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mode[[i]], main = paste("Effective size vs mode est at Tu=", M[i,1])); abline(h = range(target_v[[i]]), col="red" )})
dev.off()
effS[[1]]
pdf("results_out_red1.pdf"); par(mfrow=c(2,2))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mean[[i]], xlim=c(0,150), main = paste("true vs mean est at Tu=", M[i,1])))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mode[[i]], xlim=c(0,150),main = paste("true vs mode est at Tu=", M[i,1])))
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mean[[i]],main = paste("Effective size vs mean est at Tu=", M[i,1])); abline(h = range(target_v[[i]]), col="red" )})
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mode[[i]], main = paste("Effective size vs mode est at Tu=", M[i,1])); abline(h = range(target_v[[i]]), col="red" )})
dev.off()
pdf("results_out_red1.pdf"); par(mfrow=c(2,2))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mean[[i]], xlim=c(0,150), main = paste("true vs mean est at Tu=", M[i,1])))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mode[[i]], xlim=c(0,150),main = paste("true vs mode est at Tu=", M[i,1])))
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mean[[i]],main = paste("Effective size vs mean est at Tu=", M[i,1])); abline(h = range(target_v[[i]]),xlim=c(0,150), col="red" )})
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mode[[i]], main = paste("Effective size vs mode est at Tu=", M[i,1])); abline(h = range(target_v[[i]]),xlim=c(0,150), col="red" )})
dev.off()
pdf("results_out_red1.pdf"); par(mfrow=c(2,2))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mean[[i]], xlim=c(0,150), main = paste("true vs mean est at Tu=", M[i,1])))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mode[[i]], xlim=c(0,150),main = paste("true vs mode est at Tu=", M[i,1])))
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mean[[i]],main = paste("Effective size vs mean est at Tu=", M[i,1])); abline(h = range(target_v[[i]]),xlim=c(0,150), col="red" )})
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mode[[i]], main = paste("Effective size vs mode est at Tu=", M[i,1])); abline(h = range(target_v[[i]]),xlim=c(0,150), col="red" )})
dev.off()
pdf("results_out_red1.pdf"); par(mfrow=c(2,2))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mean[[i]], xlim=c(0,150), main = paste("true vs mean est at Tu=", M[i,1])))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mode[[i]], xlim=c(0,150),main = paste("true vs mode est at Tu=", M[i,1])))
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mean[[i]],xlim=c(0,150),main = paste("Effective size vs mean est at Tu=", M[i,1])); abline(h = range(target_v[[i]]), col="red" )})
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mode[[i]],xlim=c(0,150), main = paste("Effective size vs mode est at Tu=", M[i,1])); abline(h = range(target_v[[i]]), col="red" )})
dev.off()
pdf("results_out_red2.pdf"); par(mfrow=c(2,2))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mean[[i]], xlim=c(0,150), main = paste("true vs mean est at Tu=", M[i,1])))
#sapply(seq(n), function(i) plot(target_v[[i]], est_v_mode[[i]], xlim=c(0,150),main = paste("true vs mode est at Tu=", M[i,1])))
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mean[[i]],xlim=c(0,150),main = paste("Effective size vs mean est at Tu=", M[i,1])); abline(h = range(target_v[[i]]), col="red" )})
sapply(seq(n), function(i){ plot(effS[[i]], est_v_mode[[i]],xlim=c(0,150), main = paste("Effective size vs mode est at Tu=", M[i,1])); abline(h = range(target_v[[i]]), col="red" )})
dev.off()
mean(effS[[1]]<40)
length(effS[[1]])
sum(effS[[1]]<40)
sum(effS[[2]]<40)
mean(effS[[2]]<40)
sum(effS[[1]]<40 & est_v_mean[[1]]>5)
sum(effS[[1]]<40 & est_v_mean[[1]]>3)
sum(effS[[2]]<40 & est_v_mean[[2]]>3)
sum(effS[[2]]<40 & est_v_mean[[2]]>10)
sum(effS[[2]]<40 & est_v_mode[[2]]>10)
sum(effS[[1]]<40 & est_v_mode[[1]]>10)
sum(effS[[1]]<40 & est_v_mode[[1]]>3)
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Type 1 error + power/w post. mean of u/Eu/1.RData")
res_tot <- res
setwd("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Type 1 error + power/w post. mean of u/Eu/")
load("2.RData")
length(res_tot)
length(res_tot[[1]])
res_tot[[1]] <- append(res_tot[[1]], res[[1]])
length(res_tot[[1]])
n_p <-integer(length(index <- ceiling(M[,1]*10+1)[sapply(res,length) > 0]))
props <- seq(0,100,10)[index]
n_meth <- length( (method_used = c('MCMCglmm_mean','MCMCglmm_mode','MCMCglmm_mean_1M_iter','MCMCglmm_mode_1M_iter', 'CERAMIC')) )
power_mat = matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used))
# type1err <- matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used))
n_pvals <- NULL
for(k in index){
# assign(paste0('p_vals',k,'_t1err'), vector("list", n_meth)) # List for the methods
assign(paste0('p_vals',k,'_pow'), vector("list", n_meth)) # List for the methods
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
# eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
if(any(is.na(res[[k]][[j]]$Po))){
res[[k]][[j]]$Po[3:4] <- res[[k]][[j]]$Po[1:2]
}
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[k] = n_p[k] + 1; }
}
}
}
# index <- 1:6
level <- .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',k,',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
Tu_vals <- props/100
plot_power(na.omit(power_mat), Tu_vals, method_used)
plot_power <- function(power_mat, props, meth_list){
sds <- 2*sqrt(.25 / n_p)
n_method <- length(meth_list)
col_vec <- rainbow(n_method)
pch_vec <- 14 + seq(n_method)
pdf("power_plot.pdf")
errbar(props, (y<-power_mat[,1]), y+sds, y-sds, type = "b", pch=pch_vec[1], col=col_vec[1], errbar.col = col_vec[1], ylim = c(0,1), cap = .03,
ylab = "Power", xlab = "Proportion of variance on logit scale due to polygenic effects/covariates", xaxt = "n" )
for(i in 2:n_method){
errbar(props, (y<-power_mat[,i]), y+sds, y-sds, type = "b",add=T, cap = .03,pch = pch_vec[i], col= col_vec[i], errbar.col = col_vec[i])
}
axis(1, at = props, label = paste(props*100, (1-props)*100, sep = "/") )
legend('topright', horiz = F, legend = meth_list, pch = pch_vec , col = col_vec, cex=1.4, bty="n")
dev.off()
power_mat
}
plot_power(na.omit(power_mat), Tu_vals, method_used)
eff_siz
res[[1]][[1]]
n_p <-integer(length(index <- ceiling(M[,1]*10+1)[sapply(res,length) > 0]))
props <- seq(0,100,10)[index]
n_meth <- length( (method_used = c('MCMCglmm_mean','MCMCglmm_mode','MCMCglmm_mean_1M_iter','MCMCglmm_mode_1M_iter', 'CERAMIC')) )
power_mat = matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used))
effSizes <- matrix(NA, n_rep, 2)
n_pvals <- NULL
for(k in index){
# assign(paste0('p_vals',k,'_t1err'), vector("list", n_meth)) # List for the methods
assign(paste0('p_vals',k,'_pow'), vector("list", n_meth)) # List for the methods
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
# eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
if(any(is.na(res[[k]][[j]]$Po))){
res[[k]][[j]]$Po[3:4] <- res[[k]][[j]]$Po[1:2]
}
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
effSizes[j,] <- res[[k]][[j]]$effSizes
if (i ==1) n_p[k] = n_p[k] + 1; }
}
}
}
head(effSizes)
sum(effSizes[,1]<effSizes[,2])
summary(effSizes)
power_mat_highS = matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used))
cond1 <- effSizes[,1] > 40
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat_highS[',k,',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x[cond1]<level)))')))
}
sum(cond1)
cond1 <- effSizes[,2] > 40
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat_highS[',k,',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x[cond1]<level)))')))
}
sum(cond1)
power_mat
# index <- 1:6
level <- .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',k,',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
power_mat
power_mat_highS
plot_power(power_mat_highS)
plot_power(power_mat_highS,props = Tu, meth_list = method_used)
plot_power(power_mat_highS,props = Tu_vals, meth_list = method_used)
dev.off()
plot_power(power_mat_highS,props = Tu_vals, meth_list = method_used)
M
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/12-19-2016/Project 1 - VTnocov - 1pct thresh - Wasc/tv_noG_1K_highPrev.RData")
p_valsMCMC <- vector("list", n_M) # List of size n_M
est_varMCMC <- vector("list", n_M)
for(i in 1:n_M) {
for (j in 1:n_rep){
if (! any(res[[i]][[j]][[1]] < 0)) p_valsMCMC[[i]] <- append(p_valsMCMC[[i]], res[[i]][[j]][[1]])
est_varMCMC[[i]] <- append(est_varMCMC[[i]], res[[i]][[j]][[2]])
}
}
pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/12-19-2016/Project 1 - VTnocov - 1pct thresh - Wasc/tv_G.RData")
p_valsMCMC <- vector("list", n_M) # List of size n_M
est_varMCMC <- vector("list", n_M)
for(i in 1:n_M) {
for (j in 1:n_rep){
if (! any(res[[i]][[j]][[1]] < 0)) p_valsMCMC[[i]] <- append(p_valsMCMC[[i]], res[[i]][[j]][[1]])
est_varMCMC[[i]] <- append(est_varMCMC[[i]], res[[i]][[j]][[2]])
}
}
pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
round(lapply(p_valsMCMC, pvals_analysis),4)
round(lapply(p_valsMCMC, pvals_analysis)[[1]],4)
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/12-19-2016/Project 1 - VTnocov - 1pct thresh - Wasc/tv_noG_5C_lowPrev.RData")
p_valsMCMC <- vector("list", n_M) # List of size n_M
est_varMCMC <- vector("list", n_M)
for(i in 1:n_M) {
for (j in 1:n_rep){
if (! any(res[[i]][[j]][[1]] < 0)) p_valsMCMC[[i]] <- append(p_valsMCMC[[i]], res[[i]][[j]][[1]])
est_varMCMC[[i]] <- append(est_varMCMC[[i]], res[[i]][[j]][[2]])
}
}
pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/12-19-2016/Project 1 - VTnocov - 1pct thresh - Wasc/tv_noG_highPrevAddVarSampSizCut.RData")
p_valsMCMC <- vector("list", n_M) # List of size n_M
est_varMCMC <- vector("list", n_M)
for(i in 1:n_M) {
for (j in 1:n_rep){
if (! any(res[[i]][[j]][[1]] < 0)) p_valsMCMC[[i]] <- append(p_valsMCMC[[i]], res[[i]][[j]][[1]])
est_varMCMC[[i]] <- append(est_varMCMC[[i]], res[[i]][[j]][[2]])
}
}
pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
e*1e2
3*1e2
3*1e3
1/3000
1/3001
1/301
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Type 1 error + power/BLUE_center/w cond_mean/B.RData")
setwd("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With peds + missing G/Type 1 error + power/BLUE_center/w cond_mean/")
plot_power <- function(power_mat, props, meth_list){
sds <- 2*sqrt(.25 / n_p)
n_method <- length(meth_list)
col_vec <- rainbow(n_method)
pch_vec <- 14 + seq(n_method)
pdf("power_plot.pdf")
errbar(props, (y<-power_mat[,1]), y+sds, y-sds, type = "b", pch=pch_vec[1], col=col_vec[1], errbar.col = col_vec[1], ylim = c(0,1), cap = .03,
ylab = "Power", xlab = "Proportion of variance on logit scale due to polygenic effects/covariates", xaxt = "n" )
for(i in 2:n_method){
errbar(props, (y<-power_mat[,i]), y+sds, y-sds, type = "b",add=T, cap = .03,pch = pch_vec[i], col= col_vec[i], errbar.col = col_vec[i])
}
axis(1, at = props, label = paste(props*100, (1-props)*100, sep = "/") )
legend('topright', horiz = F, legend = meth_list, pch = pch_vec , col = col_vec, cex=1.4, bty="n")
dev.off()
power_mat
}
pvals_analysis <- function(p_vals, al){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result$Err_rate[alpha==al]
}
draw_pval <- function(ind, p_vals_list, meth_list, percent){
p_vals <- p_vals_list[[ind]]
method <- meth_list[ind]
n <- length(p_vals)
uni2 <- rank(p_vals, ties.method='max'); names(uni2)=c()
plot(-log10(uni2/(n+1)),-log10(p_vals), type="n", ylab=expression('Observed (-log'[10]*' p-value)'), xlab=expression('Expected (-log'[10]*' p-value)'))
a=1:n
high <- qbeta(0.025, a, rev(a))
low <- qbeta(0.975, a, rev(a))
polygon(-log10(c(a/n,rev(a/n))), -log10(c(high, rev(low))), col ='gray', border = NA)
points(-log10(uni2/(n+1)),-log10(p_vals), pch=16,cex=.3)
title(expression(bold('Plot of observed vs. expected -log'[10]*' p-values')),line=2)
title(paste('With', method), line=.5)
abline(a=0,b=1,col="red")
}
n_p <-integer(length(index <- ceiling(M[,1]*10+1)[sapply(res,length) > 0]))
props <- seq(0,100,10)[index]
n_meth <- length( (method_used = c('MCMCglmm','CERAMIC')) )
power_mat = matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used))
type1err <- matrix(NA, length(n_p), n_meth, dimnames = list(paste(props, 100-props, sep = "/"), method_used)); effS <- matrix(NA, n_rep,n_M)
n_pvals <- NULL
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", n_meth)) # List for the methods
assign(paste0('p_vals',k,'_pow'), vector("list", n_meth)) # List for the methods
}
for(i in 1:n_meth){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])'))); effS[j,k] <- res[[k]][[j]]$effectiveSize
if (i ==1) n_p[k] = n_p[k] + 1; }
}
}
}
# index <- 1:6
level <- .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',k,',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
Tu_vals <- props/100
plot_power(na.omit(power_mat), Tu_vals, method_used)
# Type 1 Error
props <- seq(0,100,by=10)
for(k in 1:length(index)){
eval(parse(text=paste0('type1err[',k,',] <- unlist(lapply(p_vals',index[k],'_t1err, pvals_analysis, al = .05))')))
eval(parse(text=paste0('n_pvals[',k,'] <- length(p_vals',index[k],'_t1err[[1]])')))
}
type1err;t(sapply(n_pvals, function(x).05 + c(-1,1)*2*sqrt(.05*(1-.05)/x)))
png("t1err_plot%01d.png", width = 12, height = 9, units = 'in', res=200)
par(mfrow = c(2,2))
for(k in 1:length(index)){
eval(parse(text=paste0('lapply(1:n_meth, draw_pval, p_vals',index[k],'_t1err, method_used)')))
title(paste('Polygenic effect / Covariates:',props[index[k]],'/',100-props[index[k]]), outer=TRUE, cex=1.1, line = -1.5)
}
dev.off()
M
