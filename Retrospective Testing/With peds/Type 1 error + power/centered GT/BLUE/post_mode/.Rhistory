i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
?COS
?cos
cos(18*pi/180)
76*sin(18*pi/180)
cos(18*pi/180)*76
cos(52*pi/180)*121
sin(52*pi/180)*121
23.485-146.775
sqrt(146.775^2+123.29^2)
a <- pi/180
75*cos(22*a)+117*cos(55*a)
75*sin(22*a)-117*sin(55*a)
75*sin(22*a)-117*sin((360-55)*a)
75*sin(22*a)+117*sin((360-55)*a)
sin(305*a)*117
75*sin(22*a)
28.1-95.8
69.5 +67.1
28.1+- 95.8
tanh(67.74529/136.6472)
?tan
atan(67.74529/136.6472)
atan(76.7/ 136.6 )
atan(67.74529/136.6472*a)
atan(67.74529/136.6472/a)
b=67.74529/136.6472
b
tanh(b)
atan(b)
atan(2)
b
tan(26.1*a)
tan(26.4*a)
arctan(.496)
atan(.496)
atan(67.6/136.6)
atan(67.6/136.6)/a
atan(b)/a
sin(305*a)
-sin(55*a)
121/76
121-76
72.3+74.5
76*cos(18*a)
76*sin(18*a)
121*sin(52*a)
121*cos(52*a)
72.3+74.5
23.5-95.3
23.485-95.349
sqrt(146.775^2+71.864^2)
23.5-95.3
sqrt(146.8^2+71.8^2)
atan(71.8/146.8)/a
23.5+95.3
sqrt(9.8*117.348/sin(2*27*pi/180))
x<-NULL
X = append(X, c(2:5))
x = append(x, c(2:5))
x
library(rmvnorm)
5 %in% 6:8
7 %in% 6:8
`+`(x,1)
x
libary(mvtnorm)
library(mvtnorm)
?rmvnorm
ep(x)
rep(x)
rmvnorm(1)
rmvnorm(1, mean = 0, sigma = diag(4))
rmvnorm(1, mean = rep(0,4), sigma = diag(4))
class(rmvnorm(1, mean = rep(0,4), sigma = diag(4)))
class(c(rmvnorm(1, mean = rep(0,4), sigma = diag(4))))
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/C Code/Project/Permutation based methods/Binary trait/Results/MCMCglmm/05-09-2016/Project 2 - WS - Cauchy 10 - 50k Yp - 200Yr - w covs_unobsG/1pct thresh/at 40%/B.RData")
lapply(p_valsMCMC, pvals_analysis)
pvals_analysis <- function(p_vals){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result
}
lapply(p_valsMCMC, pvals_analysis)
ls()
p_valsMCMC <- vector("list", n_M) # List of size n_M
est_varMCMC <- vector("list", n_M)
m <- length(res[[1]][[1]]) # Number of pvals + est add var
for(i in 1:n_M) {
for (j in 1:n_rep){
if (!any(res[[i]][[j]][-m] < 0)) p_valsMCMC[[i]] <- append(p_valsMCMC[[i]], res[[i]][[j]][-m])
est_varMCMC[[i]] <- append(est_varMCMC[[i]], res[[i]][[j]][m])
}
}
lapply(p_valsMCMC, pvals_analysis)
M = rbind(c(0,1.1))
n_M = dim(M)[1]
G1<-1:10
write.table(c("SNP1",G1),'geno.txt',row.names=FALSE, col.names=FALSE, sep='\t')
write(c("SNP1",G1),'geno.txt',row.names=FALSE, col.names=FALSE, sep='\t')
write(c("SNP1",G1),'geno.txt', sep='\t', ncolumns = 11)
library(GMMAT)
1078.94-925
start <- 1078.94-925
start + 50 + 120
start + 50 + 120 - 50 - 50 - 23
start + 50 + 120 - 50 - 50 - 23 - 1000
start + 50 + 120 - 50 - 50 - 23 - 1000 - 35
start + 50 + 120 - 50 - 50 - 23 - 1000 - 35 + 1035
176.63*1.03
height<- rnorm(10000, 170, 13)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
summary(list(s1,s2))
lapply(list(s1,s2), summary)
lapply(list(s1,s2), fivenum)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
s1<- sample(height, 100, replace = F)
s2<- sample(height, 1000, replace = F)
lapply(list(s1,s2), sd)
hist(list(s1,s2)
)
lapply(list(s1,s2), hist)
(100-183)/24
(110-183)/24
(120-183)/24
(115-183)/24
(115-145)/25
(195-183)/24
qnorm(.5, lower.tail = F)
pnorm(.5, lower.tail = F)
(195-145)/25
pnorm(2, lower.tail = F)
R.home()
system("echo $HOME")
q()
.000023
y<-rnorm(100)
edit(y)
q(save = F)
?@
?'@'
install.packages("MCMCglmm")
sd(c(1,3,4,5,7))
sd(c(1,3,4,5,7))*sqrt(4/5)
?sd
mean(1:5)
mean(c(2,1,4,6,5))
sd(1:5)*sqrt(4/5)
sd(1:5)
sd(c(2,1,4,6,5))*sqrt(4/5)
mean(c(6,0,-2,0,6))
mean(c(-4,-2,0,2,4))
mean((x<-c(-4,-2,0,2,4)))
mean((y<-c(6,0,-2,0,6)))
cor(x,y)
sd(x)*sqrt(4/5)
sd(y)*sqrt(4/5)
mean((x/2.83)*(y-2)/3.35)
mean(x*y)
qnorm(.05)*.5
pnorm(qnorm(.05)*.5)
pnorm(qnorm(.8)*.5)
pnorm(qnorm(.5)*.5)
4/2.7*.25*2.5+63
-4/2.7*.25*2.5+63
sqrt(1-.6^2)*15
plot_power <- function(power_mat){
na_i <- n_p > 0
props <- seq(0,100,by=20)[na_i]
sds <- 2*sqrt(.25/n_p[na_i])
pdf("power_plot.pdf")
errbar(props, (y<-power_mat[na_i,1]), y+sds, y-sds, type = "b", pch=16, col='red', errbar.col = 'red', ylim = c(0,1), cap = .03,
ylab = "Power", xlab = "Proportion of variance on logit scale due to polygenic effects/covariates", xaxt = "n" )
for(i in 2:4){
errbar(props, (y<-power_mat[na_i,i]), y+sds, y-sds, type = "b",add=T, cap = .03,pch = c(15,17,18)[i-1], col=c('blue','lightgreen','purple')[i-1], errbar.col = c('blue','lightgreen','purple')[i-1])
}
axis(1, at = props, label = c("0/100", "20/80","40/60","60/40","80/20","100/0")[na_i])
legend('topright', horiz = F, legend = c('MCMCglmm', 'GMMAT','CARAT','CERAMIC'), pch = c(16,15,17,18), col = c('red','blue','lightgreen','purple'), cex=1.4, bty="n")
dev.off()
}
pvals_analysis <- function(p_vals, al){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result$Err_rate[alpha==al]
}
draw_pval <- function(ind, p_vals_list, meth_list, percent){
p_vals <- p_vals_list[[ind]]
method <- meth_list[ind]
n <- length(p_vals)
uni2 <- rank(p_vals, ties.method='max'); names(uni2)=c()
plot(-log10(uni2/(n+1)),-log10(p_vals), type="n", ylab=expression('Observed (-log'[10]*' p-value)'), xlab=expression('Expected (-log'[10]*' p-value)'))
a=1:n
high <- qbeta(0.025, a, rev(a))
low <- qbeta(0.975, a, rev(a))
polygon(-log10(c(a/n,rev(a/n))), -log10(c(high, rev(low))), col ='gray', border = NA)
points(-log10(uni2/(n+1)),-log10(p_vals), pch=16,cex=.3)
title(expression(bold('Plot of observed vs. expected -log'[10]*' p-values')),line=2)
title(paste('With', method), line=.5)
abline(a=0,b=1,col="red")
}
n_p=rep(0, n_M)
method_used = c('MCMCglmm', 'GMMAT','CARAT','CERAMIC')
power_mat <- matrix(NA, n_M, 4)
type1err <- matrix(NA, n_M, 4, dimnames = list(NULL, method_used))
for(k in 1:n_M){
assign(paste0('p_vals',k,'_t1err'), vector("list", 4)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", 4)) # List for 4 methods
}
for(i in 1:4){
for(j in 1:n_rep){
for(k in 1:n_M){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',k,'_t1err[[',i,']] <- append(p_vals',k,'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',k,'_pow[[',i,']] <- append(p_vals',k,'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[k] = n_p[k] + 1; }
}
}
}
level <- .05
# Power
for(k in 1:n_M){
eval(parse(text=paste0('power_mat[',k,',] <- unlist(lapply(p_vals',k,'_pow, function(x) mean(x<level)))')))
}
power_mat
res[[6]][[1]]
props <- seq(0,100,by=20)
n_pvals <- NULL
for(k in 1:n_M){
eval(parse(text=paste0('type1err[',k,',] <- unlist(lapply(p_vals',k,'_t1err, pvals_analysis, al = .05))')))
eval(parse(text=paste0('n_pvals[',k,'] <- length(p_vals',k,'_t1err[[1]])')))
}
write.table(type1err, row.names=FALSE, quote=FALSE); t(sapply(n_pvals, function(x).05 + c(-1,1)*2*sqrt(.05*(1-.05)/x)))
png("t1err_plot%d.png", width = 12, height = 9, units = 'in', res=200)
par(mfrow = c(2,2))
for(k in 1:n_M){
eval(parse(text=paste0('lapply(1:4, draw_pval, p_vals',k,'_t1err, method_used)')))
title(paste('Polygenic effect / Covariates:',props[k],'/',100-props[k]), outer=TRUE, cex=1.1, line = -1.5)
}
dev.off()
library(Hmisc)
plot_power(power_mat)
p_vals6_t1err
str(p_vals6_t1err)
summary(p_vals6_t1err[[1]])
hist(p_vals6_t1err[[1]])
min(p_vals6_t1err[[1]])
head(sort(p_vals6_t1err[[1]]))
head(sort(p_vals6_t1err[[2]]))
require(MCMCglmm)
?MCMCglmm
?rbeta
edit(rbeta)
edit(rbeta)
library(Matrix)
?Matrix::`dgCMatrix-class`
?as
?cor
?cov
edit(cov)
sum(c(1,2),c(5,10))
sum(as.vector(c(1,2)),as.vector(c(5,10)))
c(1,2)+c(5,10))
c(1,2)+c(5,10)
?scale
?dcauchy
load("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With related individuals + missing G/Type 1 error + power/old settings/.RData")
res
sqrt(.05*.95/5000)
?predcit.MCMCglmm
?MCMCglmm::predict.MCMCglmm
edit(predict.MCMCglmm)
library(MCMCglmm)
edit(predict.MCMCglmm)
edit(predict.MCMCglmm)
?@
?'@'
n_M
n_M@
n_M
slot(Prec,x)
slot(Prec,n_M)
slot(Prec)
slot(Prec,"attr")
slotNames(Prec)
Prec@i
Prec@x
Prec$x
str(Prec)
str(Prec@x)
dim(Prec@x)
edit(predict.MCMCglmm)
update.packages("MCMCglmm")
edit(MCMCglmm::predict.MCMCglmm())
edit(MCMCglmm::predict.MCMCglmm
)
predict.MCMCglmm
update.packages("MCMCglmm")
setwd("C:/Users/JOELLE/Google Drive/Reasearch Mary Sara _ SAMSUNG/Permutation based methods/Binary trait/Results/MCMCglmm/Project - assoc mapping w binary traits/With related individuals + missing G/Type 1 error + power/w cond_mode/")
load("A.RData")
plot_power <- function(power_mat){
na_i <- n_p > 0
props <- seq(0,100,by=20)[na_i]
sds <- 2*sqrt(.25/n_p[na_i])
pdf("power_plot.pdf")
errbar(props, (y<-power_mat[na_i,1]), y+sds, y-sds, type = "b", pch=16, col='red', errbar.col = 'red', ylim = c(0,1), cap = .03,
ylab = "Power", xlab = "Proportion of variance on logit scale due to polygenic effects/covariates", xaxt = "n" )
for(i in 2:4){
errbar(props, (y<-power_mat[na_i,i]), y+sds, y-sds, type = "b",add=T, cap = .03,pch = c(15,17,18)[i-1], col=c('blue','lightgreen','purple')[i-1], errbar.col = c('blue','lightgreen','purple')[i-1])
}
axis(1, at = props, label = c("0/100", "20/80","40/60","60/40","80/20","100/0")[na_i])
legend('topright', horiz = F, legend = c('MCMCglmm', 'GMMAT','CARAT','CERAMIC'), pch = c(16,15,17,18), col = c('red','blue','lightgreen','purple'), cex=1.4, bty="n")
dev.off()
}
pvals_analysis <- function(p_vals, al){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result$Err_rate[alpha==al]
}
draw_pval <- function(ind, p_vals_list, meth_list, percent){
p_vals <- p_vals_list[[ind]]
method <- meth_list[ind]
n <- length(p_vals)
uni2 <- rank(p_vals, ties.method='max'); names(uni2)=c()
plot(-log10(uni2/(n+1)),-log10(p_vals), type="n", ylab=expression('Observed (-log'[10]*' p-value)'), xlab=expression('Expected (-log'[10]*' p-value)'))
a=1:n
high <- qbeta(0.025, a, rev(a))
low <- qbeta(0.975, a, rev(a))
polygon(-log10(c(a/n,rev(a/n))), -log10(c(high, rev(low))), col ='gray', border = NA)
points(-log10(uni2/(n+1)),-log10(p_vals), pch=16,cex=.3)
title(expression(bold('Plot of observed vs. expected -log'[10]*' p-values')),line=2)
title(paste('With', method), line=.5)
abline(a=0,b=1,col="red")
}
n_p=rep(0, 6)
method_used = c('MCMCglmm', 'GMMAT','CARAT','CERAMIC')
power_mat = matrix(NA, 6, 4)
type1err <- matrix(NA, 6, 4, dimnames = list(NULL, method_used))
index <- (1:6)[lapply(res,length) >0]
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", 4)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", 4)) # List for 4 methods
}
index
str(res)
dim(res)
length(res)
lapply(res,length) >0
index=1
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", 4)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", 4)) # List for 4 methods
}
plot_power <- function(power_mat){
na_i <- n_p > 0
props <- seq(0,100,by=20)[na_i]
sds <- 2*sqrt(.25/n_p[na_i])
pdf("power_plot.pdf")
errbar(props, (y<-power_mat[na_i,1]), y+sds, y-sds, type = "b", pch=16, col='red', errbar.col = 'red', ylim = c(0,1), cap = .03,
ylab = "Power", xlab = "Proportion of variance on logit scale due to polygenic effects/covariates", xaxt = "n" )
for(i in 2:4){
errbar(props, (y<-power_mat[na_i,i]), y+sds, y-sds, type = "b",add=T, cap = .03,pch = c(15,17,18)[i-1], col=c('blue','lightgreen','purple')[i-1], errbar.col = c('blue','lightgreen','purple')[i-1])
}
axis(1, at = props, label = c("0/100", "20/80","40/60","60/40","80/20","100/0")[na_i])
legend('topright', horiz = F, legend = c('MCMCglmm', 'GMMAT','CARAT','CERAMIC'), pch = c(16,15,17,18), col = c('red','blue','lightgreen','purple'), cex=1.4, bty="n")
dev.off()
}
pvals_analysis <- function(p_vals, al){
n <- length(p_vals); i <- 1
alpha <- c(.005,.01,.05)
result <- data.frame("alpha" = alpha, "Err_rate" = NA,"SE" = NA,"p_value" = NA)
for(a in alpha){
result$p_value[i] <- prop.test(x = sum(p_vals < a), n, p = a)$'p.val'
result$Err_rate[i] <- round(as.numeric(prop.test(x = sum(p_vals < a), n, p = a)$'est'),4)
result$SE[i] <- round(sqrt(mean(p_vals < a)*(1-mean(p_vals < a)) / n),4)
i <- i + 1
}; result$Err_rate[alpha==al]
}
draw_pval <- function(ind, p_vals_list, meth_list, percent){
p_vals <- p_vals_list[[ind]]
method <- meth_list[ind]
n <- length(p_vals)
uni2 <- rank(p_vals, ties.method='max'); names(uni2)=c()
plot(-log10(uni2/(n+1)),-log10(p_vals), type="n", ylab=expression('Observed (-log'[10]*' p-value)'), xlab=expression('Expected (-log'[10]*' p-value)'))
a=1:n
high <- qbeta(0.025, a, rev(a))
low <- qbeta(0.975, a, rev(a))
polygon(-log10(c(a/n,rev(a/n))), -log10(c(high, rev(low))), col ='gray', border = NA)
points(-log10(uni2/(n+1)),-log10(p_vals), pch=16,cex=.3)
title(expression(bold('Plot of observed vs. expected -log'[10]*' p-values')),line=2)
title(paste('With', method), line=.5)
abline(a=0,b=1,col="red")
}
n_p=rep(0, 6)
method_used = c('MCMCglmm', 'GMMAT','CARAT','CERAMIC')
power_mat = matrix(NA, 6, 4)
type1err <- matrix(NA, 6, 4, dimnames = list(NULL, method_used))
index=1
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", 4)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", 4)) # List for 4 methods
}
for(i in 1:4){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[index[k]] = n_p[index[k]] + 1; }
}
}
}
load("A.RData")
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", 4)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", 4)) # List for 4 methods
}
for(i in 1:4){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[index[k]] = n_p[index[k]] + 1; }
}
}
}
load("B.RData")
index=3
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", 4)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", 4)) # List for 4 methods
}
for(i in 1:4){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[index[k]] = n_p[index[k]] + 1; }
}
}
}
load("C.RData")
index=5
for(k in index){
assign(paste0('p_vals',k,'_t1err'), vector("list", 4)) # List for 4 methods
assign(paste0('p_vals',k,'_pow'), vector("list", 4)) # List for 4 methods
}
for(i in 1:4){
for(j in 1:n_rep){
for(k in 1:length(index)){
if(is.double(unlist(res[[k]][[j]]))){
eval(parse(text=paste0('p_vals',index[k],'_t1err[[',i,']] <- append(p_vals',index[k],'_t1err[[',i,']] , res[[',k,']][[',j,']]$Ty[,',i,'])')))
eval(parse(text=paste0('p_vals',index[k],'_pow[[',i,']] <- append(p_vals',index[k],'_pow[[',i,']] , res[[',k,']][[',j,']]$Po[',i,'])')))
if (i ==1) n_p[index[k]] = n_p[index[k]] + 1; }
}
}
}
index=c(1,3,5)
level <- .05
# Power
for(k in 1:length(index)){
eval(parse(text=paste0('power_mat[',index[k],',] <- unlist(lapply(p_vals',index[k],'_pow, function(x) mean(x<level)))')))
}
library(Hmisc)
plot_power(power_mat)
props <- seq(0,100,by=20)
for(k in 1:length(index)){
eval(parse(text=paste0('type1err[',index[k],',] <- unlist(lapply(p_vals',index[k],'_t1err, pvals_analysis, al = .05))')))
}
type1err;
png("t1err_plot%01d.png", width = 12, height = 9, units = 'in', res=200)
par(mfrow = c(2,2))
for(k in 1:length(index)){
eval(parse(text=paste0('lapply(1:4, draw_pval, p_vals',index[k],'_t1err, method_used)')))
title(paste('Polygenic effect / Covariates:',props[index[k]],'/',100-props[index[k]]), outer=TRUE, cex=1.1, line = -1.5)
}
dev.off()
